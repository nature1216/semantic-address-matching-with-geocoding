{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "VbWobh_TUvfv"
      },
      "source": [
        "# Training \"Dense Passage Retrieval\" Model\n",
        "\n",
        "using haystack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM2YBeYtUvfw"
      },
      "source": [
        "## Installing Haystack\n",
        "\n",
        "`pip`를 이용한 Haystack 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_Zg0iEaDUvfw",
        "outputId": "0fed672e-54a9-4bb5-8270-73ca5e5b5ef9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 2.5 MB/s eta 0:00:00\n",
            "Installing collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.3.1\n",
            "Collecting farm-haystack[colab,inference,metrics]\n",
            "  Downloading farm_haystack-1.22.1-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting boilerpy3 (from farm-haystack[colab,inference,metrics])\n",
            "  Downloading boilerpy3-1.0.7-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting events (from farm-haystack[colab,inference,metrics])\n",
            "  Downloading Events-0.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting httpx (from farm-haystack[colab,inference,metrics])\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference,metrics]) (4.19.2)\n",
            "Collecting lazy-imports==0.3.1 (from farm-haystack[colab,inference,metrics])\n",
            "  Downloading lazy_imports-0.3.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference,metrics]) (10.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference,metrics]) (3.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference,metrics]) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference,metrics]) (9.4.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference,metrics]) (4.0.0)\n",
            "Collecting posthog (from farm-haystack[colab,inference,metrics])\n",
            "  Downloading posthog-3.1.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting prompthub-py==4.0.0 (from farm-haystack[colab,inference,metrics])\n",
            "  Downloading prompthub_py-4.0.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference,metrics]) (1.10.13)\n",
            "Collecting quantulum3 (from farm-haystack[colab,inference,metrics])\n",
            "  Downloading quantulum3-0.9.0-py3-none-any.whl (10.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.7/10.7 MB 4.0 MB/s eta 0:00:00\n",
            "Collecting rank-bm25 (from farm-haystack[colab,inference,metrics])\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference,metrics]) (2.31.0)\n",
            "Collecting requests-cache<1.0.0 (from farm-haystack[colab,inference,metrics])\n",
            "  Downloading requests_cache-0.9.8-py3-none-any.whl (48 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.7/48.7 kB 3.2 MB/s eta 0:00:00\n",
            "Collecting scikit-learn>=1.3.0 (from farm-haystack[colab,inference,metrics])\n",
            "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting sseclient-py (from farm-haystack[colab,inference,metrics])\n",
            "  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference,metrics]) (8.2.3)\n",
            "Collecting tiktoken>=0.5.1 (from farm-haystack[colab,inference,metrics])\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference,metrics]) (4.66.1)\n",
            "Collecting transformers==4.34.1 (from farm-haystack[colab,inference,metrics])\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl.metadata (121 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.5/121.5 kB 6.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: huggingface-hub>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference,metrics]) (0.19.4)\n",
            "Collecting sentence-transformers>=2.2.0 (from farm-haystack[colab,inference,metrics])\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.0/86.0 kB 4.6 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting mlflow (from farm-haystack[colab,inference,metrics])\n",
            "  Downloading mlflow-2.9.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting rapidfuzz<2.8.0,>=2.0.15 (from farm-haystack[colab,inference,metrics])\n",
            "  Downloading rapidfuzz-2.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 10.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference,metrics]) (1.11.4)\n",
            "Collecting seqeval (from farm-haystack[colab,inference,metrics])\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 2.7 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting pillow (from farm-haystack[colab,inference,metrics])\n",
            "  Downloading Pillow-9.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.3/4.3 MB 12.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from prompthub-py==4.0.0->farm-haystack[colab,inference,metrics]) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[colab,inference,metrics]) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[colab,inference,metrics]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[colab,inference,metrics]) (23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[colab,inference,metrics]) (2023.6.3)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers==4.34.1->farm-haystack[colab,inference,metrics])\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[colab,inference,metrics]) (0.4.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]==4.34.1; extra == \"inference\"->farm-haystack[colab,inference,metrics]) (2.1.0+cu118)\n",
            "Collecting accelerate>=0.20.3 (from transformers[sentencepiece,torch]==4.34.1; extra == \"inference\"->farm-haystack[colab,inference,metrics])\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece,torch]==4.34.1; extra == \"inference\"->farm-haystack[colab,inference,metrics])\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 11.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]==4.34.1; extra == \"inference\"->farm-haystack[colab,inference,metrics]) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.5.0->farm-haystack[colab,inference,metrics]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.5.0->farm-haystack[colab,inference,metrics]) (4.5.0)\n",
            "Collecting jarowinkler<2.0.0,>=1.2.0 (from rapidfuzz<2.8.0,>=2.0.15->farm-haystack[colab,inference,metrics])\n",
            "  Downloading jarowinkler-1.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.2/114.2 kB 5.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,inference,metrics]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,inference,metrics]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,inference,metrics]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,inference,metrics]) (2023.11.17)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,inference,metrics]) (1.4.4)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,inference,metrics]) (23.1.0)\n",
            "Collecting cattrs>=22.2 (from requests-cache<1.0.0->farm-haystack[colab,inference,metrics])\n",
            "  Downloading cattrs-23.2.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting url-normalize>=1.4 (from requests-cache<1.0.0->farm-haystack[colab,inference,metrics])\n",
            "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[colab,inference,metrics]) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[colab,inference,metrics]) (3.2.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.0->farm-haystack[colab,inference,metrics]) (0.16.0+cu118)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.0->farm-haystack[colab,inference,metrics]) (3.8.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[colab,inference,metrics]) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx->farm-haystack[colab,inference,metrics])\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[colab,inference,metrics]) (1.3.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->farm-haystack[colab,inference,metrics])\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 3.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab,inference,metrics]) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab,inference,metrics]) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab,inference,metrics]) (0.13.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[colab,inference,metrics]) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[colab,inference,metrics]) (2.2.1)\n",
            "Collecting databricks-cli<1,>=0.8.7 (from mlflow->farm-haystack[colab,inference,metrics])\n",
            "  Downloading databricks_cli-0.18.0-py2.py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[colab,inference,metrics]) (0.4)\n",
            "Collecting gitpython<4,>=2.1.0 (from mlflow->farm-haystack[colab,inference,metrics])\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: pytz<2024 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[colab,inference,metrics]) (2023.3.post1)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[colab,inference,metrics]) (6.8.0)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[colab,inference,metrics]) (0.4.4)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow->farm-haystack[colab,inference,metrics])\n",
            "  Downloading alembic-1.13.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting docker<7,>=4.0.0 (from mlflow->farm-haystack[colab,inference,metrics])\n",
            "  Downloading docker-6.1.3-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[colab,inference,metrics]) (2.2.5)\n",
            "Collecting querystring-parser<2 (from mlflow->farm-haystack[colab,inference,metrics])\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[colab,inference,metrics]) (2.0.23)\n",
            "Requirement already satisfied: pyarrow<15,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[colab,inference,metrics]) (9.0.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[colab,inference,metrics]) (3.5.1)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[colab,inference,metrics]) (3.7.1)\n",
            "Collecting gunicorn<22 (from mlflow->farm-haystack[colab,inference,metrics])\n",
            "  Downloading gunicorn-21.2.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[colab,inference,metrics]) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack[colab,inference,metrics]) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack[colab,inference,metrics]) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog->farm-haystack[colab,inference,metrics])\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog->farm-haystack[colab,inference,metrics])\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from quantulum3->farm-haystack[colab,inference,metrics]) (7.0.0)\n",
            "Collecting num2words (from quantulum3->farm-haystack[colab,inference,metrics])\n",
            "  Downloading num2words-0.5.13-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[sentencepiece,torch]==4.34.1; extra == \"inference\"->farm-haystack[colab,inference,metrics]) (5.9.5)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow->farm-haystack[colab,inference,metrics])\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache<1.0.0->farm-haystack[colab,inference,metrics]) (1.2.0)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->farm-haystack[colab,inference,metrics]) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->farm-haystack[colab,inference,metrics]) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->farm-haystack[colab,inference,metrics]) (0.9.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker<7,>=4.0.0->mlflow->farm-haystack[colab,inference,metrics]) (1.6.4)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow->farm-haystack[colab,inference,metrics]) (3.0.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow->farm-haystack[colab,inference,metrics]) (2.1.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=2.1.0->mlflow->farm-haystack[colab,inference,metrics])\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow->farm-haystack[colab,inference,metrics]) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow->farm-haystack[colab,inference,metrics]) (2.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow->farm-haystack[colab,inference,metrics]) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow->farm-haystack[colab,inference,metrics]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow->farm-haystack[colab,inference,metrics]) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow->farm-haystack[colab,inference,metrics]) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow->farm-haystack[colab,inference,metrics]) (3.1.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow->farm-haystack[colab,inference,metrics]) (3.0.1)\n",
            "Collecting huggingface-hub>=0.5.0 (from farm-haystack[colab,inference,metrics])\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[sentencepiece,torch]==4.34.1; extra == \"inference\"->farm-haystack[colab,inference,metrics]) (1.12)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[sentencepiece,torch]==4.34.1; extra == \"inference\"->farm-haystack[colab,inference,metrics]) (2.1.0)\n",
            "Collecting docopt>=0.6.2 (from num2words->quantulum3->farm-haystack[colab,inference,metrics])\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow->farm-haystack[colab,inference,metrics])\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[sentencepiece,torch]==4.34.1; extra == \"inference\"->farm-haystack[colab,inference,metrics]) (1.3.0)\n",
            "Downloading prompthub_py-4.0.0-py3-none-any.whl (6.9 kB)\n",
            "Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.7/7.7 MB 27.1 MB/s eta 0:00:00\n",
            "Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.8/10.8 MB 27.0 MB/s eta 0:00:00\n",
            "Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 33.9 MB/s eta 0:00:00\n",
            "Downloading boilerpy3-1.0.7-py3-none-any.whl (22 kB)\n",
            "Downloading Events-0.5-py3-none-any.whl (6.8 kB)\n",
            "Downloading farm_haystack-1.22.1-py3-none-any.whl (856 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 856.0/856.0 kB 27.5 MB/s eta 0:00:00\n",
            "Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 75.0/75.0 kB 4.9 MB/s eta 0:00:00\n",
            "Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76.9/76.9 kB 5.1 MB/s eta 0:00:00\n",
            "Downloading mlflow-2.9.1-py3-none-any.whl (19.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.1/19.1 MB 36.6 MB/s eta 0:00:00\n",
            "Downloading posthog-3.1.0-py2.py3-none-any.whl (37 kB)\n",
            "Downloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
            "Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 265.7/265.7 kB 14.6 MB/s eta 0:00:00\n",
            "Downloading alembic-1.13.0-py3-none-any.whl (230 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 230.6/230.6 kB 14.1 MB/s eta 0:00:00\n",
            "Downloading cattrs-23.2.3-py3-none-any.whl (57 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 3.4 MB/s eta 0:00:00\n",
            "Downloading databricks_cli-0.18.0-py2.py3-none-any.whl (150 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 150.3/150.3 kB 9.6 MB/s eta 0:00:00\n",
            "Downloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 148.1/148.1 kB 9.0 MB/s eta 0:00:00\n",
            "Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 190.6/190.6 kB 12.4 MB/s eta 0:00:00\n",
            "Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.2/80.2 kB 5.2 MB/s eta 0:00:00\n",
            "Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 54.7 MB/s eta 0:00:00\n",
            "Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 295.0/295.0 kB 13.1 MB/s eta 0:00:00\n",
            "Downloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.3/143.3 kB 10.1 MB/s eta 0:00:00\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 3.5 MB/s eta 0:00:00\n",
            "Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.6/78.6 kB 5.5 MB/s eta 0:00:00\n",
            "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: sentence-transformers, seqeval, docopt\n",
            "  Building wheel for sentence-transformers (setup.py): started\n",
            "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=c71e984be1a4d52761a084c13a3ba349c519810a8fee5c90a3c8098111619442\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=5d4e5d6de3db1b0d2df3daf5178909796b7bf14d4e927a303b74b314d24497c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for docopt (setup.py): started\n",
            "  Building wheel for docopt (setup.py): finished with status 'done'\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=c2f163098d679a51691d0f08665567b3926f8526d66d84d5b47818e8ef0bd7a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built sentence-transformers seqeval docopt\n",
            "Installing collected packages: sseclient-py, sentencepiece, monotonic, events, docopt, url-normalize, smmap, rank-bm25, querystring-parser, pillow, num2words, Mako, lazy-imports, jarowinkler, h11, gunicorn, cattrs, boilerpy3, backoff, tiktoken, scikit-learn, requests-cache, rapidfuzz, prompthub-py, posthog, huggingface-hub, httpcore, gitdb, docker, databricks-cli, alembic, tokenizers, seqeval, quantulum3, httpx, gitpython, accelerate, transformers, mlflow, sentence-transformers, farm-haystack\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.19.4\n",
            "    Uninstalling huggingface-hub-0.19.4:\n",
            "      Successfully uninstalled huggingface-hub-0.19.4\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed Mako-1.3.0 accelerate-0.25.0 alembic-1.13.0 backoff-2.2.1 boilerpy3-1.0.7 cattrs-23.2.3 databricks-cli-0.18.0 docker-6.1.3 docopt-0.6.2 events-0.5 farm-haystack-1.22.1 gitdb-4.0.11 gitpython-3.1.40 gunicorn-21.2.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 huggingface-hub-0.17.3 jarowinkler-1.2.3 lazy-imports-0.3.1 mlflow-2.9.1 monotonic-1.6 num2words-0.5.13 pillow-9.0.0 posthog-3.1.0 prompthub-py-4.0.0 quantulum3-0.9.0 querystring-parser-1.2.4 rank-bm25-0.2.2 rapidfuzz-2.7.0 requests-cache-0.9.8 scikit-learn-1.3.2 sentence-transformers-2.2.2 sentencepiece-0.1.99 seqeval-1.2.2 smmap-5.0.1 sseclient-py-1.8.0 tiktoken-0.5.2 tokenizers-0.14.1 transformers-4.34.1 url-normalize-1.4.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "pip install --upgrade pip\n",
        "pip install farm-haystack[colab,inference,metrics]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow_probability==0.12.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOFDXbAaEQ23",
        "outputId": "11c9ca84-9914-48e0-a281-d613144c3652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_probability==0.12.2\n",
            "  Downloading tensorflow_probability-0.12.2-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.12.2) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.12.2) (1.23.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.12.2) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.12.2) (2.2.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.12.2) (0.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.12.2) (0.1.8)\n",
            "Installing collected packages: tensorflow_probability\n",
            "  Attempting uninstall: tensorflow_probability\n",
            "    Found existing installation: tensorflow-probability 0.22.0\n",
            "    Uninstalling tensorflow-probability-0.22.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.22.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.0.6 requires tensorflow-probability>=0.13.0, but you have tensorflow-probability 0.12.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorflow_probability-0.12.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRCcNFymUvfx"
      },
      "source": [
        "### Enabling Telemetry\n",
        "[Telemetry](https://docs.haystack.deepset.ai/docs/telemetry) 자세한 내용 참고"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMnDz7XFUvfx"
      },
      "outputs": [],
      "source": [
        "from haystack.telemetry import tutorial_running\n",
        "\n",
        "tutorial_running(9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "hyM1YV4QUvfx"
      },
      "source": [
        "## Logging\n",
        "\n",
        "haystack의 로깅 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "yFHKb2dxUvfx"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XsqOPfKTUvfx"
      },
      "outputs": [],
      "source": [
        "# Here are some imports that we'll need\n",
        "\n",
        "from haystack.nodes import DensePassageRetriever\n",
        "from haystack.utils import fetch_archive_from_http\n",
        "from haystack.document_stores import InMemoryDocumentStore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "-sSlxbfAUvfx"
      },
      "source": [
        "## Training Data\n",
        "\n",
        "DPR 모델을 훈련하려면 질문과 관련 문서의 쌍을 만들어야 한다.\n",
        "\n",
        "모델을 훈련하기 위해서는 원본 DPR 훈련 데이터와 동일한 형식의 데이터셋이 필요하다. 데이터셋의 각 데이터는 다음과 같은 구조를 가져야 합니다.\n",
        "\n",
        "``` python\n",
        "    {\n",
        "        \"dataset\": str,\n",
        "        \"question\": str,\n",
        "        \"answers\": list of str\n",
        "        \"positive_ctxs\": list of dictionaries of format {'title': str, 'text': str, 'score': int, 'title_score': int, 'passage_id': str}\n",
        "        \"negative_ctxs\": list of dictionaries of format {'title': str, 'text': str, 'score': int, 'title_score': int, 'passage_id': str}\n",
        "        \"hard_negative_ctxs\": list of dictionaries of format {'title': str, 'text': str, 'score': int, 'title_score': int, 'passage_id': str}\n",
        "    }\n",
        "```\n",
        "\n",
        "`positive_ctxs`는 쿼리에 대한 정답이다. 어떤 데이터셋에서는 쿼리에 대해 여러 개의 positive 문맥이 있을 수 있으므로 `num_positives` 매개변수를 기본값 1보다 높게 설정할 수 있다. 그러나  `num_positives` 는 데이터의 각 쿼리에 대한 최소`positive_ctxs` 수 이하이어야 한다. positive 문맥이 예제당 불균형하게 있는 경우 답을 포함하는 비슷한 문맥을 검색하여 일부 소프트 레이블을 생성하는 것이 좋다.\n",
        "\n",
        "DPR은 표준적으로 in-batch negatives라고 알려진 방법을 사용하여 훈련된다. 이는 특정 쿼리의 positive 문맥이 배치 내 다른 쿼리에 대한 negative 문맥으로 취급된다는 것을 의미한다. 이렇게 함으로써 모델이 대규모 데이터에 대해 훈련될 수 있도록 높은 정도의 계산 효율성을 달성할 수 있다.\n",
        "\n",
        "`negative_ctxs` 는 Haystack의 DPR 훈련에서 실제로 사용되지 않으므로 빈 목록으로 설정하는 것이 좋다. 이들은 원래의 DPR 저자들에 의해 in-batch negatives 방법과 비교하기 위한 실험에서 사용되었다.\n",
        "\n",
        "`hard_negative_ctxs` 는 쿼리와 관련이 없는 passage이다. 원래의 DPR 논문에서 이러한 passage는 쿼리에 가장 관련 있는 passage를 찾기 위해 리트리버를 사용하여 가져온다. 답변 텍스트를 포함하는 passage는 필터링된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "G10vxgGDUvfx"
      },
      "source": [
        "## Using Question Answering Data\n",
        "\n",
        "Question Answering datasets은 훈련 데이터로 사용될 수 있다. Google의 Natural Questions 데이터셋은 충분히 크며 충분히 고유한 passage를 포함하고 있어 DPR 훈련 세트로 변환할 수 있다. 이를 단순히 답을 포함하는 passage를 쿼리에 대한 관련 문서로 간주하여 수행한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "5nnLKlJxUvfx"
      },
      "source": [
        "## Download Original DPR Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "B_mF_mxMUvfx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ef7058a-b124-4cab-a226-a53c4e31b913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.utils.import_utils:Fetching from https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-train.json.gz to 'data/tutorial9/train'\n",
            "INFO:haystack.utils.import_utils:Fetching from https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-dev.json.gz to 'data/tutorial9/dev'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Download original DPR data\n",
        "# WARNING: the train set is 7.4GB and the dev set is 800MB\n",
        "\n",
        "doc_dir = \"data/tutorial9\"\n",
        "\n",
        "s3_url_train = \"https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-train.json.gz\"\n",
        "s3_url_dev = \"https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-dev.json.gz\"\n",
        "\n",
        "fetch_archive_from_http(s3_url_train, output_dir=doc_dir + \"/train\")\n",
        "fetch_archive_from_http(s3_url_dev, output_dir=doc_dir + \"/dev\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "cCKm6YzEUvfx"
      },
      "source": [
        "## Option 1: Training DPR from Scratch\n",
        "\n",
        "passage 및 query embedding model 모두 BERT base를 사용하여 초기화되며 모델은 Google의 Natural Questions 데이터셋으로 훈련된다\n",
        "(DPR에 특화된 형식으로)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6qjNP4OVUvfx"
      },
      "outputs": [],
      "source": [
        "# Here are the variables to specify our training data, the models that we use to initialize DPR\n",
        "# and the directory where we'll be saving the model\n",
        "\n",
        "train_filename = \"/content/dpr_train_neg_yh.json\"\n",
        "dev_filename = \"/content/dpr_train_neg_yh.json\"\n",
        "\n",
        "query_model = \"kykim/bert-kor-base\"\n",
        "passage_model = \"kykim/bert-kor-base\"\n",
        "\n",
        "save_dir = \"../saved_models/dpr\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "RRbgoBKkUvfx"
      },
      "source": [
        "## Option 2: Finetuning DPR\n",
        "\n",
        "데이터 셋에 맞추어 사전훈련된 bert model을 finr-tuning하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tilvNLE5Uvfx"
      },
      "outputs": [],
      "source": [
        "# Here are the variables you might want to use instead of the set above\n",
        "# in order to perform pretraining\n",
        "\n",
        "# doc_dir = \"PATH_TO_YOUR_DATA_DIR\"\n",
        "# train_filename = \"TRAIN_FILENAME\"\n",
        "# dev_filename = \"DEV_FILENAME\"\n",
        "\n",
        "# query_model = \"facebook/dpr-question_encoder-single-nq-base\"\n",
        "# passage_model = \"facebook/dpr-ctx_encoder-single-nq-base\"\n",
        "\n",
        "# save_dir = \"../saved_models/dpr\"\n",
        "\n",
        "# Here are the variables to specify our training data, the models that we use to initialize DPR\n",
        "# and the directory where we'll be saving the model\n",
        "\n",
        "train_filename = \"/content/dpr_train_neg_yh.json\"\n",
        "dev_filename = \"/content/dpr_train_neg_yh.json\"\n",
        "\n",
        "query_model = \"kykim/bert-kor-base\"\n",
        "passage_model = \"kykim/bert-kor-base\"\n",
        "\n",
        "save_dir = \"../saved_models/dpr\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "35e_74_dUvfx"
      },
      "source": [
        "## Initialization\n",
        "\n",
        "\n",
        "모델을 훈련하려면 일반 언어 모델 가중치로 초기화하거나 파인튜닝을 위해 사전 훈련된 DPR 가중치로 초기화할 수 있다. 원본 DPR 매개변수를 따르되 통과 길이의 최대값은 그대로 유지하고 쿼리 길이의 최대값은 64로 설정한다. 이는 쿼리가 매우 길지 않기 때문이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "AaDD5ZdIUvfy",
        "outputId": "10b3c3f0-1cc2-42a7-cbde-128c245886d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216,
          "referenced_widgets": [
            "c76d0577d769469da814604b0ff855e8",
            "d6ab4cf78d3744cfb23bf53e0428aa9e",
            "40e7fc24363d409196edc4e37be80d33",
            "3e4c4c3441ba4970bfc901f3f54169e9",
            "3a6052ba519646de901dae02622662ff",
            "2562a56d0bd745f5bb00e7f75c38dcbf",
            "13e1a6f21fa04daf897cfe5db50f3e2e",
            "7faedf0e39da46278d0ec3caa448a30e",
            "efa7c728284f47c5accb78583e4a5b75",
            "73607cc3e5f54140ba31c238606fa58e",
            "c51a8091b49d4bd0b5bb7fb00fa6b38f",
            "0810a38b1fb9458aa65e05ab14e38fa9",
            "e52ac4d467ad45bdbb7916163364118f",
            "cd00e18733d94e4eb126132ad5331610",
            "ab5d09eace4d46978c715a843197c3ae",
            "3f6d256c87fe43fb919cb1496c44437b",
            "62707a28918b4dea85ee414118544b19",
            "6fed862d3e7348d5bbefed21c7603a8c",
            "587cf35cb5b144dd809a126ffacc6e70",
            "0dcec195ed6b4ca5abde7bf55cd40d9b",
            "dd8b5c12d75543f59058b461abfd4ae5",
            "a0b86ce2534b48c3946f8f54204816af",
            "6ee40d38fb1d40ed8788e41b6993d552",
            "4b8713905aa443ff8d5a7150cc45367c",
            "65047265afc244c99fe3d1d99df7ae1d",
            "f878e7e5f9454b9f863e08489516faa6",
            "a73509ff9c7f4184ada7018c93ce4f8b",
            "f5ac1ef8ce6f4e7ca63fe3754945fa2d",
            "0cf80b62278c4a9ba5d3551e2d12cbdf",
            "2a3c65b8a2a54a978c99b78d885e55c8",
            "ad75ea2dcc984d69b2773512eba9969c",
            "c37b4ddf26624f56ad8c7391044ae7cc",
            "43eca387e9cc48b1888bc2fc810c7d7d",
            "65e3ebf6694c47a1941dced9eacf22f5",
            "99e9a699ca4e4edf9fc3cd472d8c37ae",
            "1a110997ecfe4d43abd8c6838e9c612f",
            "2ac0088faa9a41f19780e543575a46a9",
            "12d7473b2a074f25a2275b39afc84453",
            "d4b8d1ca7d6a47888e1e86e8b4424944",
            "ea8a4c2317af4ea38006247d98577f66",
            "5db1c2028ac44a15b065d70db20da67b",
            "b8b374a4cf8b4ba59cd20a33cfbd81fe",
            "b26d29210b43471a90414fae24dd02a1",
            "07c3aa575baa4272a6ea9b2fca8349cf"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CPU - Number of GPUs: 0\n",
            "INFO:haystack.modeling.utils:Using devices: CPU - Number of GPUs: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/80.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c76d0577d769469da814604b0ff855e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0810a38b1fb9458aa65e05ab14e38fa9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/344k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ee40d38fb1d40ed8788e41b6993d552"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/476M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65e3ebf6694c47a1941dced9eacf22f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n",
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n"
          ]
        }
      ],
      "source": [
        "## Initialize DPR model\n",
        "\n",
        "retriever = DensePassageRetriever(\n",
        "    document_store=InMemoryDocumentStore(),\n",
        "    query_embedding_model=query_model,\n",
        "    passage_embedding_model=passage_model,\n",
        "    max_seq_len_query=64,\n",
        "    max_seq_len_passage=256,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "01TaB74gUvfy"
      },
      "source": [
        "## Training\n",
        "\n",
        "훈련을 시작하는 코드.\n",
        "\n",
        "V100 GPU에서는 배치 크기 16까지 맞출 수 있으므로 그래디언트 누적 단계를 8로 설정하여 원래 DPR 실험의 배치 크기 128을 시뮬레이션한다.\n",
        "\n",
        "embed_title=True일 때 문서 제목은 입력 텍스트 시퀀스 앞에 [SEP] 토큰과 함께 추가된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_U9sIm-yUvfy",
        "outputId": "9f82984c-91e3-4769-d276-7a23c6d7a6cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|\n",
            " (o)(o)------'\\ _ /     ( )\n",
            " \n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TRAIN DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:==================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading train set from: /content/dpr_train_neg_yh.json \n",
            "Preprocessing dataset:   0%|          | 0/3 [00:00<?, ? Dicts/s]ERROR:haystack.modeling.data_handler.processor:There were 1 errors during preprocessing at positions: {195}\n",
            "Preprocessing dataset:  33%|███▎      | 1/3 [00:00<00:01,  1.87 Dicts/s]ERROR:haystack.modeling.data_handler.processor:There were 2 errors during preprocessing at positions: {130, 490}\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:01<00:00,  2.47 Dicts/s]\n",
            "ERROR:haystack.modeling.data_handler.processor:Unable to convert 3 samples to features. Their ids are : 490, 130, 195\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING DEV DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading dev set from: /content/dpr_train_neg_yh.json\n",
            "Preprocessing dataset:   0%|          | 0/3 [00:00<?, ? Dicts/s]ERROR:haystack.modeling.data_handler.processor:There were 1 errors during preprocessing at positions: {154}\n",
            "Preprocessing dataset:  33%|███▎      | 1/3 [00:00<00:01,  1.89 Dicts/s]ERROR:haystack.modeling.data_handler.processor:There were 2 errors during preprocessing at positions: {344, 325}\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:01<00:00,  2.46 Dicts/s]\n",
            "ERROR:haystack.modeling.data_handler.processor:Unable to convert 3 samples to features. Their ids are : 344, 154, 325\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TEST DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading test set from: /content/dpr_train_neg_yh.json\n",
            "Preprocessing dataset:   0%|          | 0/3 [00:00<?, ? Dicts/s]ERROR:haystack.modeling.data_handler.processor:There were 2 errors during preprocessing at positions: {146, 4}\n",
            "Preprocessing dataset:  33%|███▎      | 1/3 [00:00<00:01,  1.90 Dicts/s]ERROR:haystack.modeling.data_handler.processor:There were 1 errors during preprocessing at positions: {301}\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:01<00:00,  2.49 Dicts/s]\n",
            "ERROR:haystack.modeling.data_handler.processor:Unable to convert 3 samples to features. Their ids are : 146, 4, 301\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:DATASETS SUMMARY\n",
            "INFO:haystack.modeling.data_handler.data_silo:================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in train: 1159\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in dev  : 1159\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in test : 1159\n",
            "INFO:haystack.modeling.data_handler.data_silo:Total examples   : 3477\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest query length observed after clipping: 37   - for max_query_len: 64\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average query length after clipping:          18.59879206212252\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion queries clipped:                   0.0\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:Longest passage length observed after clipping: 27.0   - for max_passage_len: 256\n",
            "INFO:haystack.modeling.data_handler.data_silo:Average passage length after clipping:          13.038826574633305\n",
            "INFO:haystack.modeling.data_handler.data_silo:Proportion passages clipped:                    0.0\n",
            "INFO:haystack.modeling.model.optimization:Loading optimizer 'AdamW': {'correct_bias': True, 'weight_decay': 0.0, 'eps': 1e-08, 'lr': 1e-05}\n",
            "INFO:haystack.modeling.model.optimization:Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO:haystack.modeling.model.optimization:Loading schedule 'get_linear_schedule_with_warmup': '{'num_warmup_steps': 100, 'num_training_steps': 18}'\n",
            "INFO:haystack.modeling.training.base:No train checkpoints found. Starting a new training ...\n",
            "Train epoch 0/1 (Cur. train loss: 32.9753): 100%|██████████| 73/73 [10:29<00:00,  8.62s/it]\n",
            "Train epoch 1/1 (Cur. train loss: 29.7690): 100%|██████████| 73/73 [10:28<00:00,  8.62s/it]\n",
            "Evaluating: 100%|██████████| 73/73 [02:25<00:00,  1.99s/it]\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 146 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "INFO:haystack.modeling.evaluation.eval:\n",
            " _________ text_similarity _________\n",
            "INFO:haystack.modeling.evaluation.eval:loss: 0.2470222892074157\n",
            "INFO:haystack.modeling.evaluation.eval:task_name: text_similarity\n",
            "INFO:haystack.modeling.evaluation.eval:acc: 0.9665602510686652\n",
            "INFO:haystack.modeling.evaluation.eval:f1: 0.4667817083692839\n",
            "INFO:haystack.modeling.evaluation.eval:acc_and_f1: 0.7166709797189745\n",
            "INFO:haystack.modeling.evaluation.eval:average_rank: 1.8921484037963763\n",
            "INFO:haystack.modeling.evaluation.eval:report: \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "hard_negative     0.9827    0.9827    0.9827     35803\n",
            "     positive     0.4668    0.4668    0.4668      1159\n",
            "\n",
            "     accuracy                         0.9666     36962\n",
            "    macro avg     0.7248    0.7248    0.7248     36962\n",
            " weighted avg     0.9666    0.9666    0.9666     36962\n",
            "\n",
            "INFO:haystack.modeling.model.biadaptive_model:prediction_head saving\n"
          ]
        }
      ],
      "source": [
        "# Start training our model and save it when it is finished\n",
        "\n",
        "retriever.train(\n",
        "    data_dir='/content/dpr_train_neg_yh.json)',\n",
        "    train_filename=train_filename,\n",
        "    dev_filename=dev_filename,\n",
        "    test_filename=dev_filename,\n",
        "    n_epochs=2,\n",
        "    batch_size=16,\n",
        "    grad_acc_steps=8,\n",
        "    save_dir=save_dir,\n",
        "    evaluate_every=3000,\n",
        "    embed_title=False,\n",
        "    num_positives=1,\n",
        "    num_hard_negatives=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "umN6QGFmUvfy"
      },
      "source": [
        "## Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jozwi13bUvfy",
        "outputId": "29be1f90-e3ea-4cf5-b719-5851c528557f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CPU - Number of GPUs: 0\n",
            "INFO:haystack.nodes.retriever.dense:DPR model loaded from ../saved_models/dpr\n"
          ]
        }
      ],
      "source": [
        "reloaded_retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.document_stores import InMemoryDocumentStore\n",
        "import pandas as pd\n",
        "#import json\n",
        "\n",
        "document_store = InMemoryDocumentStore()\n",
        "\n",
        "#train = json.load(open(train_filename))\n",
        "#dicts = [{'content':j} for j in set([i['answers'] for i in train])]\n",
        "\n",
        "train = pd.read_csv('/content/질의데이터_yh.csv')\n",
        "dicts = [{'content': j['place_info'],'meta':{'cor':j['coordinates (y, x)']}} for j in [d for idx, d in train.iterrows()]]\n",
        "\n",
        "document_store.write_documents(dicts)\n",
        "document_store.update_embeddings(reloaded_retriever)"
      ],
      "metadata": {
        "id": "FIlPCAptW3XH",
        "outputId": "5c15d58b-6e7f-4a5b-e4f2-cba7cfe65e67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CPU - Number of GPUs: 0\n",
            "INFO:haystack.document_stores.memory:Updating embeddings for 0 docs ...\n",
            "Updating Embedding:   0%|          | 0/116 [00:00<?, ? docs/s]\n",
            "Create embeddings:   0%|          | 0/128 [00:00<?, ? Docs/s]\u001b[A\n",
            "Create embeddings:  12%|█▎        | 16/128 [00:01<00:08, 13.54 Docs/s]\u001b[A\n",
            "Create embeddings:  25%|██▌       | 32/128 [00:02<00:06, 14.30 Docs/s]\u001b[A\n",
            "Create embeddings:  38%|███▊      | 48/128 [00:03<00:05, 14.17 Docs/s]\u001b[A\n",
            "Create embeddings:  50%|█████     | 64/128 [00:04<00:04, 14.13 Docs/s]\u001b[A\n",
            "Create embeddings:  62%|██████▎   | 80/128 [00:05<00:03, 13.98 Docs/s]\u001b[A\n",
            "Create embeddings:  75%|███████▌  | 96/128 [00:07<00:02, 12.95 Docs/s]\u001b[A\n",
            "Create embeddings:  88%|████████▊ | 112/128 [00:08<00:01, 12.39 Docs/s]\u001b[A\n",
            "Create embeddings: 100%|██████████| 128/128 [00:08<00:00, 15.91 Docs/s]\u001b[A\n",
            "Documents Processed: 10000 docs [00:08, 1111.96 docs/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = reloaded_retriever.retrieve(\"공대 5호관과 자연대 3호관에 있는 지름길을 알려줘\", document_store=document_store)\n",
        "for i in range(3):\n",
        "  print('top '+str(i+1)+', 장소: '+results[i].content+', coordinate: '+results[i].meta['cor'])"
      ],
      "metadata": {
        "id": "Wr932pXtW60-",
        "outputId": "faa45344-2119-434d-867f-90a276b3cb1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f0495fc28863>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreloaded_retriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"공대 5호관과 자연대 본관에 있는 지름길을 알려줘\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_store\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocument_store\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'top '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m', 장소: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m', coordinate: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'reloaded_retriever' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n6TNM1RjyfYW"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c76d0577d769469da814604b0ff855e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6ab4cf78d3744cfb23bf53e0428aa9e",
              "IPY_MODEL_40e7fc24363d409196edc4e37be80d33",
              "IPY_MODEL_3e4c4c3441ba4970bfc901f3f54169e9"
            ],
            "layout": "IPY_MODEL_3a6052ba519646de901dae02622662ff"
          }
        },
        "d6ab4cf78d3744cfb23bf53e0428aa9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2562a56d0bd745f5bb00e7f75c38dcbf",
            "placeholder": "​",
            "style": "IPY_MODEL_13e1a6f21fa04daf897cfe5db50f3e2e",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "40e7fc24363d409196edc4e37be80d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7faedf0e39da46278d0ec3caa448a30e",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efa7c728284f47c5accb78583e4a5b75",
            "value": 80
          }
        },
        "3e4c4c3441ba4970bfc901f3f54169e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73607cc3e5f54140ba31c238606fa58e",
            "placeholder": "​",
            "style": "IPY_MODEL_c51a8091b49d4bd0b5bb7fb00fa6b38f",
            "value": " 80.0/80.0 [00:00&lt;00:00, 6.47kB/s]"
          }
        },
        "3a6052ba519646de901dae02622662ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2562a56d0bd745f5bb00e7f75c38dcbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13e1a6f21fa04daf897cfe5db50f3e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7faedf0e39da46278d0ec3caa448a30e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efa7c728284f47c5accb78583e4a5b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73607cc3e5f54140ba31c238606fa58e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c51a8091b49d4bd0b5bb7fb00fa6b38f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0810a38b1fb9458aa65e05ab14e38fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e52ac4d467ad45bdbb7916163364118f",
              "IPY_MODEL_cd00e18733d94e4eb126132ad5331610",
              "IPY_MODEL_ab5d09eace4d46978c715a843197c3ae"
            ],
            "layout": "IPY_MODEL_3f6d256c87fe43fb919cb1496c44437b"
          }
        },
        "e52ac4d467ad45bdbb7916163364118f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62707a28918b4dea85ee414118544b19",
            "placeholder": "​",
            "style": "IPY_MODEL_6fed862d3e7348d5bbefed21c7603a8c",
            "value": "Downloading config.json: 100%"
          }
        },
        "cd00e18733d94e4eb126132ad5331610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_587cf35cb5b144dd809a126ffacc6e70",
            "max": 725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0dcec195ed6b4ca5abde7bf55cd40d9b",
            "value": 725
          }
        },
        "ab5d09eace4d46978c715a843197c3ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd8b5c12d75543f59058b461abfd4ae5",
            "placeholder": "​",
            "style": "IPY_MODEL_a0b86ce2534b48c3946f8f54204816af",
            "value": " 725/725 [00:00&lt;00:00, 56.3kB/s]"
          }
        },
        "3f6d256c87fe43fb919cb1496c44437b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62707a28918b4dea85ee414118544b19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fed862d3e7348d5bbefed21c7603a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "587cf35cb5b144dd809a126ffacc6e70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dcec195ed6b4ca5abde7bf55cd40d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd8b5c12d75543f59058b461abfd4ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0b86ce2534b48c3946f8f54204816af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ee40d38fb1d40ed8788e41b6993d552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b8713905aa443ff8d5a7150cc45367c",
              "IPY_MODEL_65047265afc244c99fe3d1d99df7ae1d",
              "IPY_MODEL_f878e7e5f9454b9f863e08489516faa6"
            ],
            "layout": "IPY_MODEL_a73509ff9c7f4184ada7018c93ce4f8b"
          }
        },
        "4b8713905aa443ff8d5a7150cc45367c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5ac1ef8ce6f4e7ca63fe3754945fa2d",
            "placeholder": "​",
            "style": "IPY_MODEL_0cf80b62278c4a9ba5d3551e2d12cbdf",
            "value": "Downloading vocab.txt: 100%"
          }
        },
        "65047265afc244c99fe3d1d99df7ae1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a3c65b8a2a54a978c99b78d885e55c8",
            "max": 344259,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad75ea2dcc984d69b2773512eba9969c",
            "value": 344259
          }
        },
        "f878e7e5f9454b9f863e08489516faa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c37b4ddf26624f56ad8c7391044ae7cc",
            "placeholder": "​",
            "style": "IPY_MODEL_43eca387e9cc48b1888bc2fc810c7d7d",
            "value": " 344k/344k [00:00&lt;00:00, 4.81MB/s]"
          }
        },
        "a73509ff9c7f4184ada7018c93ce4f8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5ac1ef8ce6f4e7ca63fe3754945fa2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cf80b62278c4a9ba5d3551e2d12cbdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a3c65b8a2a54a978c99b78d885e55c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad75ea2dcc984d69b2773512eba9969c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c37b4ddf26624f56ad8c7391044ae7cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43eca387e9cc48b1888bc2fc810c7d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65e3ebf6694c47a1941dced9eacf22f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99e9a699ca4e4edf9fc3cd472d8c37ae",
              "IPY_MODEL_1a110997ecfe4d43abd8c6838e9c612f",
              "IPY_MODEL_2ac0088faa9a41f19780e543575a46a9"
            ],
            "layout": "IPY_MODEL_12d7473b2a074f25a2275b39afc84453"
          }
        },
        "99e9a699ca4e4edf9fc3cd472d8c37ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4b8d1ca7d6a47888e1e86e8b4424944",
            "placeholder": "​",
            "style": "IPY_MODEL_ea8a4c2317af4ea38006247d98577f66",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "1a110997ecfe4d43abd8c6838e9c612f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5db1c2028ac44a15b065d70db20da67b",
            "max": 475782997,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8b374a4cf8b4ba59cd20a33cfbd81fe",
            "value": 475782997
          }
        },
        "2ac0088faa9a41f19780e543575a46a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b26d29210b43471a90414fae24dd02a1",
            "placeholder": "​",
            "style": "IPY_MODEL_07c3aa575baa4272a6ea9b2fca8349cf",
            "value": " 476M/476M [00:02&lt;00:00, 207MB/s]"
          }
        },
        "12d7473b2a074f25a2275b39afc84453": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4b8d1ca7d6a47888e1e86e8b4424944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea8a4c2317af4ea38006247d98577f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5db1c2028ac44a15b065d70db20da67b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8b374a4cf8b4ba59cd20a33cfbd81fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b26d29210b43471a90414fae24dd02a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07c3aa575baa4272a6ea9b2fca8349cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}